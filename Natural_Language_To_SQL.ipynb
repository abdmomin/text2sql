{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKuD5ntBB5gt0XtUI3XPNH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdmomin/text2sql/blob/main/Natural_Language_To_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a dummy Database"
      ],
      "metadata": {
        "id": "mIsUsrZKWCTW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4EL4-GZjDc3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from datetime import date, timedelta\n",
        "from sqlalchemy.orm import declarative_base, relationship, sessionmaker\n",
        "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
        "\n",
        "\n",
        "Base = declarative_base()\n",
        "\n",
        "class Customer(Base):\n",
        "    __tablename__ = 'customers'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    name = Column(String)\n",
        "    email = Column(String, unique=True)\n",
        "    orders = relationship(\"Order\", back_populates=\"customer\")\n",
        "\n",
        "class Product(Base):\n",
        "    __tablename__ = 'products'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    name = Column(String)\n",
        "    price = Column(Float)\n",
        "    orders = relationship(\"Order\", back_populates=\"product\")\n",
        "\n",
        "class Order(Base):\n",
        "    __tablename__ = 'orders'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    customer_id = Column(Integer, ForeignKey('customers.id'))\n",
        "    product_id = Column(Integer, ForeignKey('products.id'))\n",
        "    quantity = Column(Integer)\n",
        "    order_date = Column(Date)\n",
        "\n",
        "    customer = relationship(\"Customer\", back_populates=\"orders\")\n",
        "    product = relationship(\"Product\", back_populates=\"orders\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inserting data"
      ],
      "metadata": {
        "id": "S8zZ5ni_XA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('example.db'):\n",
        "\n",
        "  # Create SQLite engine\n",
        "  engine = create_engine('sqlite:///example.db')\n",
        "  Base.metadata.create_all(engine)\n",
        "\n",
        "  # Session\n",
        "  Session = sessionmaker(bind=engine)\n",
        "  session = Session()\n",
        "\n",
        "  # Sample data\n",
        "  customer_names = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Edward\", \"Fiona\", \"George\", \"Hannah\", \"Ian\", \"Julia\"]\n",
        "  product_names = [\"Laptop\", \"Smartphone\", \"Tablet\", \"Headphones\", \"Monitor\", \"Keyboard\", \"Mouse\", \"Printer\", \"Camera\", \"Router\"]\n",
        "  prices = [1200, 800, 300, 150, 250, 100, 50, 200, 500, 120]\n",
        "\n",
        "  # Add customers\n",
        "  customers = [Customer(name=name, email=f\"{name.lower()}@example.com\") for name in customer_names]\n",
        "  session.add_all(customers)\n",
        "\n",
        "  # Add products\n",
        "  products = [Product(name=name, price=price) for name, price in zip(product_names, prices)]\n",
        "  session.add_all(products)\n",
        "\n",
        "  # Commit customers and products so we can reference them by ID\n",
        "  session.commit()\n",
        "\n",
        "  # Add 10 orders\n",
        "  for i in range(10):\n",
        "      order = Order(\n",
        "          customer_id=random.choice(customers).id,\n",
        "          product_id=random.choice(products).id,\n",
        "          quantity=random.randint(1, 5),\n",
        "          order_date=date(2024, 5, 1) + timedelta(days=i)\n",
        "      )\n",
        "      session.add(order)\n",
        "\n",
        "  session.commit()\n",
        "  session.close()\n",
        "print('Database already exists')"
      ],
      "metadata": {
        "id": "hcx4fU2dV27D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import contextlib\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def sql_cursor(readonly=True):\n",
        "  conn = sqlite3.connect('example.db')\n",
        "  cursor = conn.cursor()\n",
        "  try:\n",
        "    yield cursor\n",
        "    if not readonly:\n",
        "      conn.commit()\n",
        "  except Exception:\n",
        "    if not readonly:\n",
        "      conn.rollback()\n",
        "    raise\n",
        "  finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "R3gyBNsvXJeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sql_cursor() as cursor:\n",
        "  cursor.execute('SELECT * FROM customers')\n",
        "  for row in cursor.fetchall():\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "fG8VpWBMbeg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Natural Language to SQL"
      ],
      "metadata": {
        "id": "B48xpYOXarWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q langchain-community langchain-core langgraph langchain-groq transformers langchain-huggingface"
      ],
      "metadata": {
        "id": "RluXPgQQcGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# llm = ChatGroq(model='llama-3.3-70b-versatile')\n",
        "\n",
        "# print(llm.invoke('who are you?').content)"
      ],
      "metadata": {
        "id": "MCKXmZ5xkzFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"gpt2\",\n",
        "    task=\"text-generation\",\n",
        "    pipeline_kwargs={\"max_new_tokens\": 10},\n",
        ")\n",
        "\n",
        "llm.invoke('who are you?')"
      ],
      "metadata": {
        "id": "z1HZSB6A5pyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke('what can you do?')"
      ],
      "metadata": {
        "id": "UcLKMM6D7dxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///example.db\")\n",
        "\n",
        "print(db.dialect)\n",
        "print(\"=\" * 30, \"\\n\")\n",
        "print(db.get_usable_table_names())\n",
        "print(\"=\" * 30, \"\\n\")\n",
        "print(db.get_table_info())"
      ],
      "metadata": {
        "id": "m6NKM5oBly8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "## Initial state\n",
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    sql_query: str\n",
        "    query_result: str\n",
        "    query_rows: list\n",
        "    attempts: int\n",
        "    relevance: str\n",
        "    final_answer: str\n",
        "    sql_error: bool"
      ],
      "metadata": {
        "id": "pU9nCdDnsrbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Agent 1: Determines if the user NL-input relevant to the db schema\n",
        "\n",
        "class CheckRelevance(BaseModel):\n",
        "    relevance: str = Field(\n",
        "        description=\"Indicates whether the question is related to the database schema. 'relevant' or 'not_relevant'.\"\n",
        "    )\n",
        "\n",
        "def check_relevance(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(f\"Checking relevance of the question: {question}\")\n",
        "    system = \"\"\"You are a highly skilled SQL expert. Your task is to evaluate whether a given natural language question is relevant to a database based on its schema.\n",
        "\n",
        "    Use the schema below to determine whether the question can reasonably be answered using the available tables and columns.\n",
        "\n",
        "    ---\n",
        "    Schema:\n",
        "    {schema}\n",
        "    ---\n",
        "\n",
        "    Instructions:\n",
        "    1. Carefully read the user's question.\n",
        "    2. Check whether the schema contains the necessary tables and columns to answer the question.\n",
        "    3. If the question can be answered using the schema, respond with **\"relevant\"**.\n",
        "    4. If the schema lacks the necessary information, respond with **\"not_relevant\"**.\n",
        "    5. Your response must be either **\"relevant\"** or **\"not_relevant\"** only—do not explain or elaborate.\n",
        "\n",
        "    Output Format:\n",
        "    relevant\n",
        "    or\n",
        "    not_relevant\n",
        "    \"\"\"\n",
        "    human = f\"Question: {question}\"\n",
        "    check_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", human),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    llm = ChatGroq(model='llama-3.3-70b-versatile')\n",
        "    structured_llm = llm.with_structured_output(CheckRelevance)\n",
        "    relevance_checker = check_prompt | structured_llm\n",
        "    try:\n",
        "      relevance = relevance_checker.invoke({'schema': db.get_table_info()})\n",
        "      state[\"relevance\"] = relevance.relevance.lower().strip()\n",
        "      print(f\"Relevance determined: {state['relevance']}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error during relevance check: {e}\")\n",
        "      state[\"relevance\"] = \"not_relevant\"\n",
        "      state[\"sql_error\"] = True\n",
        "    return state"
      ],
      "metadata": {
        "id": "zcx40Ie9NlHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Agent 2: Converts natural language to SQL queries\n",
        "\n",
        "class ConvertToSQL(BaseModel):\n",
        "    sql_query: str = Field(\n",
        "        description=\"The SQL query corresponding to the user's natural language question.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def convert_nl_to_sql(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(f\"Converting question to SQL for user: {question}\")\n",
        "    system = \"\"\"\n",
        "    You are a highly skilled SQL generation assistant. Your task is to convert a user's natural language question into a valid, syntactically correct, and semantically meaningful SQL query using the correct {dialect} dialect.\n",
        "\n",
        "    Follow these strict rules:\n",
        "\n",
        "    1. **Use only the tables and columns provided in the schema below**. Do not invent or reference tables/columns that are not explicitly listed.\n",
        "    2. **Understand the relationships between tables** (e.g., foreign keys, primary keys) and use JOINs accordingly where appropriate.\n",
        "    3. **Avoid using `SELECT *`**. Instead, return only the specific columns that are relevant to answering the user's question.\n",
        "    4. Use appropriate **filters, sorting, and grouping** based on the user's intent (e.g., time ranges, categories, totals).\n",
        "    5. If necessary, use **aggregations** (COUNT, AVG, MAX, etc.) when the question asks for summaries or statistics.\n",
        "    6. Maintain clarity and simplicity. Prioritize correctness over cleverness.\n",
        "\n",
        "    Before generating the SQL:\n",
        "    - Carefully analyze the user's question.\n",
        "    - Infer any implicit intent (e.g., filtering, ordering) only if it logically follows from the question.\n",
        "    - Never assume facts that are not supported by the schema or the question.\n",
        "\n",
        "    Schema:\n",
        "    {table_info}\n",
        "\n",
        "    Now, generate the SQL query that answers the following user question:\n",
        "    \"\"\".format(dialect=db.dialect, table_info=db.get_table_info())\n",
        "\n",
        "    convert_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", \"Question: {question}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    llm = ChatGroq(model='llama-3.3-70b-versatile')\n",
        "    structured_llm = llm.with_structured_output(ConvertToSQL)\n",
        "    sql_generator = convert_prompt | structured_llm\n",
        "    try:\n",
        "      result = sql_generator.invoke({\"question\": question})\n",
        "      state[\"sql_query\"] = result.sql_query.strip()\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to generate SQL: {e}\")\n",
        "      state[\"sql_query\"] = \"\"\n",
        "      state[\"sql_error\"] = True\n",
        "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "foWES7lUyoqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import QuerySQLDatabaseTool\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "## Agent 3: Executes generated SQL query -> retrieve the data from db -> returns updated state\n",
        "def execute_query(state: AgentState):\n",
        "    \"\"\"Execute SQL query and update state based on outcome.\"\"\"\n",
        "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
        "    try:\n",
        "        result = execute_query_tool.invoke(state[\"sql_query\"])\n",
        "        state[\"query_result\"] = result\n",
        "        state[\"sql_error\"] = False\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SQL execution: {e}\")\n",
        "        state[\"sql_error\"] = True\n",
        "        state[\"query_result\"] = str(e)\n",
        "    return state"
      ],
      "metadata": {
        "id": "jIuyUPk3P52F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Agent 4: Based on SQL result, generates NL answer\n",
        "def generate_answer(state: AgentState):\n",
        "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
        "    template = PromptTemplate.from_template(\n",
        "    \"\"\"You are an intelligent data assistant. Your task is to help answer the user's natural language question by using the provided SQL query and its result.\n",
        "\n",
        "    You will be given:\n",
        "    1. The original user question.\n",
        "    2. The SQL query that was generated to answer the question.\n",
        "    3. The result returned by executing that SQL query.\n",
        "\n",
        "    Use this information to provide a helpful, clear, and concise answer to the user's question. If the result is empty or insufficient to answer the question confidently, respond accordingly.\n",
        "\n",
        "    ---\n",
        "    Question: {question}\n",
        "    SQL Query: {sql_query}\n",
        "    SQL Result: {query_result}\n",
        "    ---\n",
        "\n",
        "    Final Answer:\"\"\")\n",
        "\n",
        "    llm_chain = template | llm | StrOutputParser()\n",
        "    answer = llm_chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"sql_query\": state[\"sql_query\"],\n",
        "        \"query_result\": state[\"query_result\"]\n",
        "    })\n",
        "    state[\"final_answer\"] = answer\n",
        "    return state"
      ],
      "metadata": {
        "id": "7roEgAdPOuyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Agent 5: Generates funny response if the user's query is not relevent to the db\n",
        "def generate_funny_response(state: AgentState):\n",
        "    print(\"Generating a funny response for an unrelated question.\")\n",
        "    system = \"\"\"\n",
        "    You are a witty, charming, and funny assistant whose job is to entertain users when they ask questions unrelated to the database or when no relevant answer can be provided.\n",
        "\n",
        "    Your responses should:\n",
        "    - Be playful and light-hearted.\n",
        "    - Stay appropriate and friendly.\n",
        "    - Acknowledge that the question isn't answerable via the database.\n",
        "    - Gently steer the user back on track with a smile (figuratively).\n",
        "\n",
        "    You are not required to be helpful — just be delightfully unhelpful in a clever way.\n",
        "    \"\"\"\n",
        "\n",
        "    human_message = f\"\"\"\n",
        "    The user asked a question that is unrelated to the database:\n",
        "    '{state['question']}'\n",
        "    Craft a humorous and creative response.\"\"\"\n",
        "\n",
        "    funny_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", human_message),\n",
        "    ])\n",
        "\n",
        "    llm = ChatGroq(model='llama-3.3-70b-versatile')\n",
        "    funny_response = funny_prompt | llm | StrOutputParser()\n",
        "    message = funny_response.invoke({})\n",
        "    state[\"final_answer\"] = message\n",
        "    print(\"Generated funny response.\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "7_eHvGZmQi12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Agent 6: Rewrites the og question if there isn't enough info\n",
        "class RewrittenQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The rewritten question.\")\n",
        "\n",
        "def regenerate_query(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
        "    system = \"\"\"\n",
        "    You are an expert in SQL and natural language understanding.\n",
        "\n",
        "    Your task is to **rewrite a user's natural language question** so that:\n",
        "    - It is clear, complete, and unambiguous.\n",
        "    - It is optimized to be converted into a precise and valid SQL query.\n",
        "    - All necessary details (e.g. filters, relationships between tables, required joins, and any implied logic) are included.\n",
        "    - The reformulated version preserves the intent and meaning of the original question but improves its structure for programmatic interpretation.\n",
        "\n",
        "    Avoid making assumptions not supported by the original question or schema.\n",
        "    \"\"\"\n",
        "\n",
        "    rewrite_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Original Question: {question}\\n\\nRewrite this question to make it clearer and more suitable for SQL generation, including all relevant details.\")\n",
        "    ])\n",
        "\n",
        "    llm = ChatGroq(model='llama-3.3-70b-versatile', temperature=0)\n",
        "    structured_llm = llm.with_structured_output(RewrittenQuestion)\n",
        "    rewriter = rewrite_prompt | structured_llm\n",
        "\n",
        "    rewritten = rewriter.invoke({\"question\": question})\n",
        "    state[\"rewritten_question\"] = rewritten.question\n",
        "    state[\"attempts\"] = state.get(\"attempts\", 0) + 1\n",
        "    print(f\"Rewritten question: {state['rewritten_question']}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "d4qoYYMaPidN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Conditionnal nodes\n",
        "def end_max_iter(state: AgentState):\n",
        "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
        "    state[\"query_result\"] = \"Please try again.\"\n",
        "    return state\n",
        "\n",
        "def router(state: AgentState):\n",
        "    print(\"Routing based on relevance...\")\n",
        "    if state[\"relevance\"].lower() == \"relevant\":\n",
        "        return \"convert_to_sql\"\n",
        "    else:\n",
        "        return \"generate_funny_response\"\n",
        "\n",
        "def check_attempts(state: AgentState):\n",
        "    print(f\"Attempt #{state['attempts']}\")\n",
        "    if state[\"attempts\"] < 3:\n",
        "        return \"convert_to_sql\"\n",
        "    else:\n",
        "        return \"end_max_iter\"\n",
        "\n",
        "def execute_sql(state: AgentState):\n",
        "    print(\"Routing based on SQL execution result...\")\n",
        "    if not state.get(\"sql_error\", False):\n",
        "        return \"generate_answer\"\n",
        "    else:\n",
        "        return \"regenerate_query\""
      ],
      "metadata": {
        "id": "l8cMGwpGSMp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Constructing the the Graph\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"check_relevance\", check_relevance)\n",
        "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
        "workflow.add_node(\"execute_sql\", execute_query)\n",
        "workflow.add_node(\"generate_answer\", generate_answer)\n",
        "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
        "workflow.add_node(\"regenerate_query\", regenerate_query)\n",
        "workflow.add_node(\"end_max_iter\", end_max_iter)\n",
        "\n",
        "# Conditional logic\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_relevance\",\n",
        "    router,\n",
        "    {\n",
        "        \"convert_to_sql\": \"convert_to_sql\",\n",
        "        \"generate_funny_response\": \"generate_funny_response\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"execute_sql\",\n",
        "    execute_sql,\n",
        "    {\n",
        "        \"generate_answer\": \"generate_answer\",\n",
        "        \"regenerate_query\": \"regenerate_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"regenerate_query\",\n",
        "    check_attempts,\n",
        "    {\n",
        "        \"convert_to_sql\": \"convert_to_sql\",\n",
        "        \"end_max_iter\": \"end_max_iter\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Terminal paths\n",
        "workflow.add_edge(\"generate_answer\", END)\n",
        "workflow.add_edge(\"generate_funny_response\", END)\n",
        "workflow.add_edge(\"end_max_iter\", END)\n",
        "\n",
        "# Start point\n",
        "workflow.set_entry_point(\"check_relevance\")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "5v9c6Ol7SVR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(app.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=2.0)))\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "wKdYgNy-1_Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize state\n",
        "state = {\n",
        "    \"question\": \"\",\n",
        "    \"chat_history\": [], # adding memory\n",
        "    \"sql_query\": \"\",\n",
        "    \"query_result\": \"\",\n",
        "    \"query_rows\": [],\n",
        "    \"attempts\": 0,\n",
        "    \"relevance\": \"\",\n",
        "    \"final_answer\": \"\",\n",
        "    \"sql_error\": False,\n",
        "}\n",
        "\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \").strip()\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Conversation ended.\")\n",
        "        break\n",
        "\n",
        "    state[\"question\"] = user_input\n",
        "    state[\"attempts\"] = 0  # reset attempts each new question\n",
        "\n",
        "    result = app.invoke(state)\n",
        "\n",
        "    answer = result.get(\"final_answer\", \"No response available.\")\n",
        "\n",
        "    print(f\"Assistant: {answer}\\n\")\n",
        "\n",
        "    state[\"chat_history\"].append({\"user\": user_input, \"assistant\": answer})\n"
      ],
      "metadata": {
        "id": "4soyO6Yt_8S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvBLrO6oB2O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CF6TDN1GB2KK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}